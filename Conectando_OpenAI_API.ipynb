{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwxu_9W9zfaJ"
      },
      "source": [
        "Autor:  \n",
        "Manuel Eugenio Morocho Cayamcela, PhD\n",
        "\n",
        "# Introducción al API de OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJYg4y8ozfaM"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS5_lnbazfaN"
      },
      "source": [
        "Bienvenido a este tutorial básico para usar la API de OpenAI en un Jupyter Notebook. Este tutorial cubrirá cómo generar texto utilizando el modelo GPT-3 de OpenAI.\n",
        "\n",
        "Primero, necesitarás instalar la biblioteca `openai` de Python. Puedes hacerlo ejecutando el siguiente comando en una celda de tu Jupyter Notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbU9u0NpzfaN"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ttva2VlzfaO"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bNxYGj3zfaO"
      },
      "source": [
        "Antes de poder usar la API de OpenAI, necesitarás una clave de API. Puedes obtener una registrándote en el [sitio web de OpenAI](https://openai.com/signup/). Una vez que tengas tu clave de API, puedes configurarla de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucoQG-NlzfaP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Reemplaza 'tu-clave-de-api' con tu clave de API real\n",
        "os.environ['OPENAI_API_KEY'] = 'tu-clave-de-api'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpZRks6fzfaP"
      },
      "source": [
        "**Nota:** Recuerda reemplazar `'tu-clave-de-api'` con tu clave de API real. Además, ten en cuenta que debes mantener tu clave de API segura y no compartirla con nadie.\n",
        "\n",
        "Ahora que hemos configurado nuestra clave de API, podemos usar la API de OpenAI para generar texto. Aquí hay un ejemplo de cómo hacerlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgV2gfxvzfaP",
        "outputId": "1ea62da8-7eb0-4490-def7-db6c0bf8c1b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletionMessage(content=\"In the realm of code where wonders abound,\\nThere thrives a concept both lost and found.\\nRecursion, a loop with a magical twist,\\nA process that cannot help but persist.\\n\\nLike a mirror reflecting what it sees,\\nRecursion calls itself, with effortless ease.\\nA function that, once invoked, can't resist\\nThe urge to call itself, persisting in the mist.\\n\\nIt's a dance of elegance, a loop so grand,\\nUnraveling problems with a gentle hand.\\nDivide, conquer, and conquer again,\\nRecursion's magic in a never-ending chain.\\n\\nInfinite patterns, in data structures enshrined,\\nA recursive journey through the programmer's mind.\\nWith each iteration, a problem is solved,\\nUntil the base case, its mystery resolved.\\n\\nSo fear not the recursion, embrace its might,\\nFor in the world of code, it shines so bright.\\nA poetic loop, a programmer's delight,\\nRecursion, a concept that takes flight.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
          ]
        }
      ],
      "source": [
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwJ5a-MPzfaQ"
      },
      "source": [
        "Y eso es todo! Ahora deberías ser capaz de usar la API de OpenAI para generar texto en un Jupyter Notebook. Recuerda que puedes experimentar con diferentes valores para `prompt`, `temperature` y `max_tokens` para ver cómo afectan al texto generado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvK075FyzfaR"
      },
      "source": [
        "## Generación de imágenes con OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HfdCeo8zfaR",
        "outputId": "c18d51fa-3465-4b9e-e628-187ae2b9a863"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-W20tbZtH09wd8KWlhPJ668Sc/user-3TRfUw5UEu4zE46s10mjt1HV/img-5tgNJmrBdjDGFs3XV1FuBfNf.png?st=2024-12-07T12%3A41%3A21Z&se=2024-12-07T14%3A41%3A21Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-06T22%3A48%3A06Z&ske=2024-12-07T22%3A48%3A06Z&sks=b&skv=2024-08-04&sig=xT/fmpL1r9QOTCT3zFTYcdPZHtiOd54KLFm2XqbxrJQ%3D'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=\"A photo of a cat made out of sushi\",\n",
        "  size=\"1024x1024\",\n",
        "  quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "\n",
        "image_url = response.data[0].url\n",
        "image_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfpfPSeWzfaR"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=\"a monkey in a skateboard in the space eating pizza\",\n",
        "  size=\"1024x1024\",\n",
        "  quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "\n",
        "image_url = response.data[0].url\n",
        "image_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUJPIJSZzfaR"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub_Zge9TzfaS"
      },
      "source": [
        "## Texto a voz con OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYqu0oajzfaS",
        "outputId": "9260613a-50df-4e7a-c38d-9ec9972ec76f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/8j/f0xtldm91_1c2bpdr69fxgzw0000gn/T/ipykernel_6344/1199538129.py:11: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  response.stream_to_file(\"output.mp3\")\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.audio.speech.create(\n",
        "    model=\"tts-1\",\n",
        "    voice=\"alloy\",\n",
        "    input=\"Estamos aprendiendo cómo usar los modelos de OpenAI para integrarlos a nuestros proyectos.\",\n",
        ")\n",
        "\n",
        "response.stream_to_file(\"output.mp3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg_qmuKjzfaS"
      },
      "source": [
        "## Voz a texto con OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ukb0awNazfaT",
        "outputId": "475319ca-22a5-41d6-f685-68c98b77db4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estamos aprendiendo cómo usar los modelos de OpenAI para integrarlos a nuestros proyectos.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "audio_file= open(\"/Users/eugenio/Documents/Notebooks_ArtificialIntelligence/5 - Large Language Models/output.mp3\", \"rb\")\n",
        "transcription = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  file=audio_file\n",
        ")\n",
        "print(transcription.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRbVBNPtzfaU"
      },
      "source": [
        "## Preguntando a un DataFrame de Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2qBHOWtzfaV",
        "outputId": "7cdd2fa0-2f61-4036-ec0c-d2d3696b285c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Para determinar a qué género debes destinar más recursos de publicidad, primero necesitamos analizar la distribución del género en la base de datos que proporcionaste. A continuación, calcularé el porcentaje de clientes en la base de datos que son de sexo masculino y femenino:\n",
            "\n",
            "- Número total de clientes en la base de datos: 200\n",
            "\n",
            "- Número de clientes de sexo masculino: 88\n",
            "- Número de clientes de sexo femenino: 112\n",
            "\n",
            "Calculando el porcentaje de clientes para cada género:\n",
            "\n",
            "- Porcentaje de clientes masculinos: (88 / 200) * 100 ≈ 44%\n",
            "- Porcentaje de clientes femeninos: (112 / 200) * 100 ≈ 56%\n",
            "\n",
            "Dado que en la base de datos la representación del sexo femenino es mayor (56%) que la del sexo masculino (44%), podríamos sugerir que es recomendable destinar más recursos de publicidad al género femenino. Esto se debe a que hay más clientes femeninos en la base de datos y, por lo tanto, es probable que haya una mayor demanda potencial de productos o servicios entre las mujeres.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Import the 'mall_customers.csv' file\n",
        "df = pd.read_csv('/Users/eugenio/Documents/Notebooks_ArtificialIntelligence/Datasets/mall_customers.csv')\n",
        "\n",
        "# Display the first 5 records\n",
        "df.head(5)\n",
        "\n",
        "# Convertir la tabla a una representación de cadena (string)\n",
        "df_string = df.to_string()\n",
        "\n",
        "# Pregunta sobre la edad promedio de los clientes en la tabla\n",
        "#question = \"¿Cómo diseñarías una campaña de marketing para que el segmento de clientes Alto Ingreso-Bajo Gasto incremente su puntaje de gasto?\"\n",
        "#question = \"Divide a los clientes por edades. ¿Qué canales de marketing serían más efectivos para atraer a cada grupo?\"\n",
        "question = \"¿A qué género debo destinar más recursos de publicidad tomando en cuenta la representación en la base de datos?\"\n",
        "\n",
        "# Pasar la variable al API de OpenAI\n",
        "client = OpenAI()\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a data analyst. Here is the data:\\n\" + df_string},\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Obtener la respuesta del API\n",
        "answer = response.choices[0].message.content\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vluzFqxFzfaW"
      },
      "source": [
        "Eso es todo, ahora puedes probar OpenAI en tu propio código. ¡Buena suerte!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMFivuM0zfaX"
      },
      "source": [
        "# Actividad: Creación de un Chatbot Simple con Streamlit y Modelos de Hugging Face o OpenAI\n",
        "\n",
        "## Objetivo\n",
        "Los estudiantes deberán crear una aplicación web interactiva utilizando **Streamlit** para desarrollar un chatbot simple que interactúe con el usuario. El chatbot utilizará un modelo preentrenado de **Hugging Face** o **OpenAI** para generar respuestas basadas en los prompts de texto proporcionados por el usuario. La aplicación deberá ser capaz de aceptar diferentes tipos de entradas, como texto libre o tablas de datos.\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "1. **Instalación de las dependencias:**\n",
        "   - Instala Streamlit, Hugging Face y las bibliotecas necesarias:\n",
        "     ```bash\n",
        "     pip install streamlit openai transformers pandas\n",
        "     ```\n",
        "\n",
        "2. **Crear la aplicación con Streamlit:**\n",
        "   - Desarrolla una interfaz de usuario simple que permita al usuario ingresar texto o cargar una tabla de datos como entrada.\n",
        "   - Integra el modelo de **Hugging Face** o **OpenAI** para que el chatbot procese las entradas y genere respuestas apropiadas.\n",
        "\n",
        "3. **Entrada de datos:**\n",
        "   - Los usuarios deben poder ingresar un **prompt de texto** o **cargar una tabla (CSV)** como entrada. Si se carga una tabla, el chatbot puede interactuar con los datos proporcionados.\n",
        "   - Usa Streamlit para crear campos de texto y una opción para cargar archivos.\n",
        "\n",
        "4. **Interacción con el modelo:**\n",
        "   - Conecta la entrada del usuario con el modelo de **Hugging Face** (por ejemplo, `transformers` de Hugging Face) o un modelo de **OpenAI** (GPT-3 o GPT-4).\n",
        "   - Si se carga una tabla, procesa la información para que el modelo pueda generar respuestas basadas en los datos.\n",
        "\n",
        "5. **Salida del chatbot:**\n",
        "   - Muestra la respuesta generada por el modelo en la misma página de la aplicación.\n",
        "\n",
        "6. **Pruebas:**\n",
        "   1. La aplicación funciona correctamente y el modelo es capaz de generar respuestas útiles a partir de las entradas proporcionadas.\n",
        "   2. La aplicación no genera respuestas a preguntas para contextos fuera de la base de datos.\n",
        "\n",
        "## Entregables:\n",
        "- El código de la aplicación en un archivo Python subido a la plataforma Moodle.\n",
        "- Presentación de los resultados en clase, o un video de 1min explicando el funcionamiento de la app, o un enlace a la aplicación publicada en **Streamlit Cloud**.\n",
        "\n",
        "## Criterios de evaluación:\n",
        "- Funcionamiento correcto del chatbot.\n",
        "- Interfaz de usuario sencilla y clara.\n",
        "- Implementación adecuada del modelo de IA (Hugging Face o OpenAI).\n",
        "- Uso correcto de Streamlit para crear la aplicación interactiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxgkAfvezfaY"
      },
      "source": [
        "## Referencias:\n",
        "\n",
        "- https://huggingface.co/models\n",
        "- https://auth.openai.com/\n",
        "- https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUlEBD81zfaY"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.11.14)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}